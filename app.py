import streamlit as st
from PIL import Image
import cv2
import numpy as np
import matplotlib.pyplot as plt
from plot_results_save import plot_comparison, custom_labels  # å¯¼å…¥ custom_labels
import subprocess
import os
import tempfile
from ultralytics import YOLO
import time  # å¯¼å…¥ time æ¨¡å—ç”¨äºæ·»åŠ å»¶è¿Ÿ
import base64

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(page_title="åŸºäº YOLO çš„è·¯é¢å‘æ´æ£€æµ‹ä¸åˆ†å‰²ç³»ç»Ÿ", page_icon=":road:", layout="wide")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'page' not in st.session_state:
    st.session_state.page = 'main'

if 'stop_camera_detection' not in st.session_state:
    st.session_state.stop_camera_detection = False

if 'custom_background' not in st.session_state:
    st.session_state.custom_background = None
if 'use_custom_background' not in st.session_state:
    st.session_state.use_custom_background = False

# é»˜è®¤èƒŒæ™¯è®¾ä¸º Noneï¼Œè¡¨ç¤ºä½¿ç”¨ Streamlit é»˜è®¤èƒŒ
default_background = None
def set_background(main_bg):
    if main_bg is None:
        return
    main_bg_ext = "png"
    st.markdown(
        f"""
        <style>
        .stApp {{
            background: url(data:image/{main_bg_ext};base64,{base64.b64encode(open(main_bg, "rb").read()).decode()});
            background-size: cover
        }}
        </style>
        """,
        unsafe_allow_html=True
    )
# æ¯æ¬¡é¡µé¢æ¸²æŸ“æ—¶æ£€æŸ¥å¹¶è®¾ç½®èƒŒæ™¯
if st.session_state.use_custom_background and st.session_state.custom_background:
    set_background(st.session_state.custom_background)
else:
    set_background(default_background)




# è·å– runs ç›®å½•ä¸‹çš„æ‰€æœ‰æ¨¡å‹æ–‡ä»¶
models_dir = "runs/segment"
models = {}  # ä½¿ç”¨å­—å…¸æ¥å­˜å‚¨æ¨¡å‹åå’Œå¯¹åº”çš„ best.pt æ–‡ä»¶è·¯å¾„
for root, dirs, files in os.walk(models_dir):
    if "weights" in root and "best.pt" in files:
        model_name = os.path.basename(os.path.dirname(root))
        model_path = os.path.join(root, "best.pt")
        models[model_name] = model_path

# ä¸»é¡µé¢
if st.session_state.page == 'main':

    # æ˜¾ç¤º Logo å’Œæ ‡è¯­
    logo = Image.open("logo.png")  # è¯·æ›¿æ¢ä¸ºå®é™…çš„ Logo å›¾ç‰‡è·¯å¾„
    col1, col2 = st.columns([1, 3])
    with col1:
        st.image(logo, width=150)
    with col2:
        st.title("åŸºäº YOLO çš„è·¯é¢å‘æ´æ£€æµ‹ä¸åˆ†å‰²ç³»ç»Ÿ")
        st.subheader("ç²¾å‡†æ£€æµ‹ï¼Œé«˜æ•ˆåˆ†å‰²ï¼ŒåŠ©åŠ›é“è·¯å®‰å…¨ï¼")

    # ç”¨å¡ç‰‡å¼å¸ƒå±€å±•ç¤ºåŠŸèƒ½
    st.markdown("<hr>", unsafe_allow_html=True)
    st.subheader("ç³»ç»ŸåŠŸèƒ½æ¦‚è§ˆ")

    # åˆ›å»ºä¸€ä¸ª4åˆ—å¸ƒå±€ï¼Œæ¨¡æ‹ŸåŸå§‹å¡ç‰‡å¸ƒå±€
    col1, col2, col3, col4 = st.columns(4)

    # æ¨¡æ‹Ÿå¡ç‰‡æ ·å¼ï¼ŒåŒ…è£¹æŒ‰é’®å’Œæè¿°æ–‡å­—
    with col1:
        with st.container():
            st.markdown("""
                <div style="background-color: white; padding: 20px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
                    <button style="width: 100%; background-color: #007bff; color: white; border: none; padding: 10px 0; font-size: 16px; border-radius: 8px;">æ¨¡å‹æ€§èƒ½åˆ†æ</button>
                    <p style="text-align: center;">æ·±å…¥äº†è§£æ¨¡å‹çš„å„é¡¹æ€§èƒ½æŒ‡æ ‡ã€‚</p>
                </div>
            """, unsafe_allow_html=True)

    with col2:
        with st.container():
            st.markdown("""
                <div style="background-color: white; padding: 20px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
                    <button style="width: 100%; background-color: #007bff; color: white; border: none; padding: 10px 0; font-size: 16px; border-radius: 8px;">å›¾ç‰‡æ£€æµ‹</button>
                    <p style="text-align: center;">ä¸Šä¼ å›¾ç‰‡ï¼Œå¿«é€Ÿæ£€æµ‹è·¯é¢å‘æ´ã€‚</p>
                </div>
            """, unsafe_allow_html=True)

    with col3:
        with st.container():
            st.markdown("""
                <div style="background-color: white; padding: 20px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
                    <button style="width: 100%; background-color: #007bff; color: white; border: none; padding: 10px 0; font-size: 16px; border-radius: 8px;">è§†é¢‘æ£€æµ‹</button>
                    <p style="text-align: center;">æ”¯æŒè§†é¢‘å’Œæ‘„åƒå¤´å®æ—¶æ£€æµ‹ã€‚</p>
                </div>
            """, unsafe_allow_html=True)

    with col4:
        with st.container():
            st.markdown("""
                <div style="background-color: white; padding: 20px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
                    <button style="width: 100%; background-color: #007bff; color: white; border: none; padding: 10px 0; font-size: 16px; border-radius: 8px;">è®¾ç½®</button>
                    <p style="text-align: center;">ä¸ªæ€§åŒ–å®šåˆ¶ç³»ç»Ÿç•Œé¢ã€‚</p>
                </div>
            """, unsafe_allow_html=True)

    # æ·»åŠ é—´è·
    st.markdown("<br>", unsafe_allow_html=True)  # æ·»åŠ é¢å¤–çš„é—´è·

    # ä½¿ç”¨ Streamlit åˆ—å¸ƒå±€è®©æŒ‰é’®å±…ä¸­
    _, _, center_col, _ = st.columns([1, 1, 1, 1])
    with center_col:
        if st.button("è¿›å…¥ç³»ç»Ÿ", key="main_enter_button"):
            st.balloons()
            st.toast('æ¬¢è¿è¿›å…¥ç³»ç»Ÿï¼', icon='ğŸ‰')
            time.sleep(.5)
            st.toast('æ­£åœ¨åŠ è½½åŠŸèƒ½æ¨¡å—...', icon='ğŸ’«')
            time.sleep(.5)
            st.toast('å³å°†ä¸ºæ‚¨å±•ç¤ºåŠŸèƒ½é€‰æ‹©é¡µé¢ã€‚', icon='ğŸ˜')
            time.sleep(1)
            st.session_state.page = 'function_selection'
            st.rerun()


    # # è¿›å…¥ç³»ç»ŸæŒ‰é’®
    # if st.button("è¿›å…¥ç³»ç»Ÿ", key="main_enter_button"):
    #     st.session_state.page = 'function_selection'
    #     st.rerun()



# åŠŸèƒ½é€‰æ‹©é¡µé¢
elif st.session_state.page == 'function_selection':
    def m_exit():
        msg = st.toast('æ„Ÿè°¢ä½ çš„ä½¿ç”¨ï¼', icon="ğŸ¥°")
        time.sleep(2)
        msg.toast('æ¬¢è¿ä¸‹æ¬¡å†æ¥å“¦ï¼', icon = "ğŸ’–")
    if st.button("é€€å‡ºç³»ç»Ÿ", key="function_exit_button"):
        st.snow()
        m_exit()
        time.sleep(1)
        st.session_state.page = 'main'
        st.rerun()

    # å®šä¹‰ä¾§è¾¹æ 
    with st.sidebar:
        st.title("åŠŸèƒ½é€‰æ‹©")
        selected_function = st.radio("è¯·é€‰æ‹©åŠŸèƒ½", ["æ¨¡å‹æ€§èƒ½åˆ†æ", "å›¾ç‰‡æ£€æµ‹", "è§†é¢‘æ£€æµ‹", "è®¾ç½®"])

    # # æ¨¡å‹åˆ—è¡¨
    # models = ["YOLOv5", "YOLOv6", "YOLOv7"]

    

    # æ¨¡å‹æ€§èƒ½åˆ†æç•Œé¢
    if selected_function == "æ¨¡å‹æ€§èƒ½åˆ†æ":     
        st.title("æ¨¡å‹æ€§èƒ½åˆ†æ")
        st.write("è¿™é‡Œå°†å±•ç¤ºæ¨¡å‹çš„æ€§èƒ½åˆ†æç»“æœï¼Œå¦‚å‡†ç¡®ç‡ã€å¬å›ç‡ç­‰ã€‚")

        # ç²¾åº¦æŒ‡æ ‡
        metrics = [
            'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)',
            'metrics/precision(M)', 'metrics/recall(M)', 'metrics/mAP50(M)', 'metrics/mAP50-95(M)'
        ]

        labels = [
            'Precision (B)', 'Recall (B)', 'mAP@50 (B)', 'mAP@50-95 (B)',
            'Precision (M)', 'Recall (M)', 'mAP@50 (M)', 'mAP@50-95 (M)'
        ]

        # è°ƒç”¨é€šç”¨å‡½æ•°ç»˜åˆ¶ç²¾åº¦å¯¹æ¯”å›¾
        st.subheader("Metrics")
        fig_num_before = plt.get_fignums()
        plot_comparison(metrics, labels, custom_labels, layout=(2, 4), save_dir=None)
        fig_num_after = plt.get_fignums()
        new_fig_num = [num for num in fig_num_after if num not in fig_num_before][0]
        fig_metrics = plt.figure(new_fig_num)
        st.pyplot(fig_metrics)

        # æŸå¤±æŒ‡æ ‡
        loss_metrics = [
            'train/box_loss', 'train/seg_loss', 'train/cls_loss', 'train/dfl_loss',
            'val/box_loss', 'val/seg_loss', 'val/cls_loss', 'val/dfl_loss'
        ]

        loss_labels = [
            'Train Box Loss', 'Train Seg Loss', 'Train Class Loss', 'Train DFL Loss',
            'Val Box Loss', 'Val Seg Loss', 'Val Class Loss', 'Val DFL Loss'
        ]

        # è°ƒç”¨é€šç”¨å‡½æ•°ç»˜åˆ¶æŸå¤±å¯¹æ¯”å›¾
        st.subheader("Losses")
        fig_num_before = plt.get_fignums()
        plot_comparison(loss_metrics, loss_labels, custom_labels, layout=(2, 4), save_dir=None)
        fig_num_after = plt.get_fignums()
        new_fig_num = [num for num in fig_num_after if num not in fig_num_before][0]
        fig_losses = plt.figure(new_fig_num)
        st.pyplot(fig_losses)

        


    # å›¾ç‰‡æ£€æµ‹ç•Œé¢
    elif selected_function == "å›¾ç‰‡æ£€æµ‹":
        st.title("å›¾ç‰‡æ£€æµ‹")
        # é€‰æ‹©æ¨¡å‹
        selected_model_name = st.selectbox("é€‰æ‹©æ¨¡å‹", list(models.keys()))
        selected_model = models[selected_model_name]  # è·å–å¯¹åº”çš„ best.pt æ–‡ä»¶è·¯å¾„

        # ä¸Šä¼ å›¾ç‰‡
        uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=["jpg", "jpeg", "png"])
        if uploaded_file is not None:
            st.success("å›¾ç‰‡ä¸Šä¼ æˆåŠŸï¼")
            # è¯»å–å›¾ç‰‡
            image = Image.open(uploaded_file)
            image_path = "temp_image.jpg"
            image.save(image_path)  # ä¿å­˜ä¸Šä¼ çš„å›¾ç‰‡åˆ°ä¸´æ—¶æ–‡ä»¶

            #  # è°ƒç”¨ predict_seg.py è¿›è¡Œæ£€æµ‹
            # command = f"python predict_seg.py --model {selected_model} --image {image_path}"
            # subprocess.run(command, shell=True)

            # # è¯»å– predict_seg.py ä¿å­˜çš„ç»“æœå›¾ç‰‡
            # original_image = cv2.imread(image_path)
            # segmented_image = cv2.imread('save/segmented_image.jpg')

            # è°ƒç”¨ seg_mask.py è¿›è¡Œæ£€æµ‹
            command = f"python seg_mask.py --model {selected_model} --image {image_path}"
            subprocess.run(command, shell=True)

            # è¯»å– seg_mask.py ä¿å­˜çš„ç»“æœå›¾ç‰‡
            original_image = cv2.imread(image_path)
            # segmented_image = cv2.imread('save/segmented_images.jpg')

           

            # é‡æ–°è¿è¡Œ seg_mask.py ä¸­çš„éƒ¨åˆ†ä»£ç æ¥ç”Ÿæˆ mask å›¾åƒ
            # from ultralytics import YOLO
            model = YOLO(selected_model)
            results = model.predict(original_image)
            mask_combined = np.zeros_like(original_image, dtype=np.uint8)
            for result in results:
                predicted_image = result.plot()
                for mask in result.masks.data:
                    mask = mask.cpu().numpy()
                    mask_3channel = np.stack((mask,) * 3, axis=-1) * 255
                    mask_3channel = mask_3channel.astype(np.uint8)
                    mask_combined = cv2.add(mask_combined, mask_3channel)
            mask_rgb = cv2.cvtColor(mask_combined, cv2.COLOR_BGR2RGB)

            segmented_image = original_image.copy()
            segmented_image[mask_combined[:, :, 2] != 0] = [255, 0, 0]

            # å°† BGR è½¬æ¢ä¸º RGB ä»¥ä¾¿ streamlit æ˜¾ç¤º
            original_image_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)
            segmented_image_rgb = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2RGB)

            # è¯»å–é¢„æµ‹å›¾ç‰‡
            # predicted_image = cv2.imread('save/segmented_image.jpg')
            predicted_image_rgb = cv2.cvtColor(predicted_image, cv2.COLOR_BGR2RGB)

            # æ˜¾ç¤ºåŸå›¾ã€mask å’Œåˆ†å‰²åçš„å›¾åƒå’Œé¢„æµ‹å›¾ç‰‡
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.image(original_image_rgb, caption="åŸå›¾", use_container_width=True)
            with col2:
                st.image(mask_rgb, caption="åˆ†å‰²æ©ç ", use_container_width=True)
            with col3:
                st.image(segmented_image_rgb, caption="åˆ†å‰²åçš„å›¾åƒ", use_container_width=True)
            with col4:
                st.image(predicted_image_rgb, caption="é¢„æµ‹å›¾ç‰‡", use_container_width=True)

            # # å•ç‹¬å±•ç¤ºé¢„æµ‹å›¾ç‰‡
            # st.image(predicted_image_rgb, caption="é¢„æµ‹å›¾ç‰‡", use_container_width=True)

            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            os.remove(image_path)

    # è§†é¢‘æ£€æµ‹ç•Œé¢
    elif selected_function == "è§†é¢‘æ£€æµ‹":
        st.title("è§†é¢‘æ£€æµ‹")
        # é€‰æ‹©æ¨¡å‹
        selected_model_name = st.selectbox("é€‰æ‹©æ¨¡å‹", list(models.keys()))
        selected_model = models[selected_model_name]  # è·å–å¯¹åº”çš„ best.pt æ–‡ä»¶è·¯å¾„

        # é€‰æ‹©ä¸Šä¼ è§†é¢‘è¿˜æ˜¯æ‰“å¼€æ‘„åƒå¤´
        source = st.radio("é€‰æ‹©è§†é¢‘æº", ["ä¸Šä¼ è§†é¢‘", "æ‰“å¼€æ‘„åƒå¤´"])

        if source == "ä¸Šä¼ è§†é¢‘":
            uploaded_video = st.file_uploader("ä¸Šä¼ è§†é¢‘", type=["mp4", "avi"])
            if uploaded_video is not None:
                st.success("è§†é¢‘ä¸Šä¼ æˆåŠŸï¼")
                # ä¿å­˜è§†é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
                with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as f:
                    f.write(uploaded_video.read())
                    temp_video_path = f.name

                # è·å–è§†é¢‘çš„æ€»å¸§æ•°
                cap = cv2.VideoCapture(temp_video_path)
                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                cap.release()

                # åˆ›å»ºè¿›åº¦æ¡
                progress_bar = st.progress(0)

                # è°ƒç”¨ predict_seg_video.py è¿›è¡Œè§†é¢‘æ£€æµ‹
                output_video_path = "save/segmented_video.mp4"
                if os.path.exists(output_video_path):
                    os.remove(output_video_path)

                model = YOLO(selected_model)
                cap = cv2.VideoCapture(temp_video_path)
                frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                fps = int(cap.get(cv2.CAP_PROP_FPS))
                out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))

                frame_count = 0
                frame_placeholder = st.empty()

                # åˆ›å»ºç»“æŸæ£€æµ‹æŒ‰é’®
                stop_button = st.button("ç»“æŸè§†é¢‘æ£€æµ‹", key="stop_video_detection")

                while cap.isOpened() and not stop_button:
                    ret, frame = cap.read()
                    if not ret:
                        break

                    # å¯¹æ¯ä¸€å¸§è¿›è¡Œåˆ†å‰²
                    results = model.predict(frame)

                    # å¯è§†åŒ–åˆ†å‰²ç»“æœ
                    for result in results:
                        segmented_frame = result.plot()
                        # å†™å…¥å¤„ç†åçš„å¸§åˆ°è§†é¢‘æ–‡ä»¶
                        out.write(segmented_frame)

                    # æ›´æ–°è¿›åº¦æ¡
                    frame_count += 1
                    progress_percent = frame_count / total_frames
                    progress_bar.progress(progress_percent)

                    # æ˜¾ç¤ºåˆ†å‰²ç»“æœï¼ˆå¯é€‰ï¼‰
                    frame_placeholder.image(segmented_frame, channels="BGR", use_container_width=True)

                    # æ›´æ–°æŒ‰é’®çŠ¶æ€
                    stop_button = st.session_state.get("stop_video_detection", False)

                # é‡Šæ”¾è§†é¢‘æ•è·å’Œå†™å…¥å¯¹è±¡
                cap.release()
                out.release()
                # ç§»é™¤ cv2.destroyAllWindows() è¿™è¡Œä»£ç 
                # cv2.destroyAllWindows()
                time.sleep(1)  # é‡Šæ”¾åç­‰å¾… 1 ç§’

                # æ˜¾ç¤ºå¤„ç†åçš„è§†é¢‘
                if os.path.exists(output_video_path):
                    st.video(output_video_path)

        elif source == "æ‰“å¼€æ‘„åƒå¤´":
            st.write("å³å°†æ‰“å¼€æ‘„åƒå¤´è¿›è¡Œå®æ—¶æ£€æµ‹...")
            cap = cv2.VideoCapture(0)  # æ‰“å¼€æ‘„åƒå¤´
            frame_placeholder = st.empty()
            model = YOLO(selected_model)

            # åˆ›å»ºç»“æŸæ£€æµ‹æŒ‰é’®
            if st.button("ç»“æŸæ£€æµ‹", key="start_stop_button"):
                st.session_state.stop_camera_detection = True

            while cap.isOpened() and not st.session_state.stop_camera_detection:
                ret, frame = cap.read()
                if not ret:
                    break

                # å¯¹æ¯ä¸€å¸§è¿›è¡Œåˆ†å‰²
                results = model.predict(frame)

                # å¯è§†åŒ–åˆ†å‰²ç»“æœ
                for result in results:
                    segmented_frame = result.plot()

                # æ˜¾ç¤ºåˆ†å‰²ç»“æœ
                frame_placeholder.image(segmented_frame, channels="BGR", use_container_width=True)

            # é‡Šæ”¾æ‘„åƒå¤´
            cap.release()

            # é‡ç½®ä¼šè¯çŠ¶æ€
            st.session_state.stop_camera_detection = False

    # è®¾ç½®ç•Œé¢
    elif selected_function == "è®¾ç½®":
        st.title("è®¾ç½®")
        # è®¾ç½®èƒŒæ™¯
        background_image = st.file_uploader("ä¸Šä¼ èƒŒæ™¯å›¾ç‰‡", type=["jpg", "jpeg", "png"])
        if background_image is not None:
            # ä¿å­˜ä¸Šä¼ çš„å›¾ç‰‡åˆ°æœ¬åœ°ä¸´æ—¶æ–‡ä»¶
            import tempfile
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".png")
            temp_file.write(background_image.read())
            temp_file.close()
            st.session_state.custom_background = temp_file.name
            st.session_state.use_custom_background = True
            st.write("èƒŒæ™¯å›¾ç‰‡è®¾ç½®æˆåŠŸï¼")

        # åˆ‡æ¢èƒŒæ™¯æŒ‰é’®
        if st.button("åˆ‡æ¢èƒŒæ™¯"):
            st.session_state.use_custom_background = not st.session_state.use_custom_background
            st.write("åˆ‡æ¢æˆåŠŸ")

        # æ¢å¤é»˜è®¤èƒŒæ™¯æŒ‰é’®
        if st.button("æ¢å¤é»˜è®¤èƒŒæ™¯"):
            st.session_state.use_custom_background = False
            st.session_state.custom_background = None
            st.write("å·²æ¢å¤é»˜è®¤èƒŒæ™¯")

            
